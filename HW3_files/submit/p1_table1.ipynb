{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "table1-intro",
      "metadata": {},
      "source": [
        "## Problem 1 — Table 1 (auto-generated)\n",
        "\n",
        "This notebook parses the `--- Table 1 Results ---` blocks produced by `main.py` in the `*_out` log files and formats them into Table 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "table1-parse",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /Users/slrpz/Downloads/ECE361E/HW3_files/table1.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training accuracy [%]</th>\n",
              "      <th>Test accuracy [%]</th>\n",
              "      <th>Total time for training [s]</th>\n",
              "      <th>Number of trainable parameters</th>\n",
              "      <th>FLOPs [M]</th>\n",
              "      <th>GPU memory during training [MB]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VGG11</td>\n",
              "      <td>99.07</td>\n",
              "      <td>76.08</td>\n",
              "      <td>1468.63</td>\n",
              "      <td>9,750,922</td>\n",
              "      <td>306.6M</td>\n",
              "      <td>939.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VGG16</td>\n",
              "      <td>98.35</td>\n",
              "      <td>78.46</td>\n",
              "      <td>1622.58</td>\n",
              "      <td>15,245,130</td>\n",
              "      <td>627.5M</td>\n",
              "      <td>2037.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MOBILENET-V1</td>\n",
              "      <td>99.37</td>\n",
              "      <td>78.47</td>\n",
              "      <td>1754.20</td>\n",
              "      <td>3,217,226</td>\n",
              "      <td>96.0M</td>\n",
              "      <td>1263.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Model Training accuracy [%] Test accuracy [%]  \\\n",
              "0         VGG11                 99.07             76.08   \n",
              "1         VGG16                 98.35             78.46   \n",
              "2  MOBILENET-V1                 99.37             78.47   \n",
              "\n",
              "  Total time for training [s] Number of trainable parameters FLOPs [M]  \\\n",
              "0                     1468.63                      9,750,922    306.6M   \n",
              "1                     1622.58                     15,245,130    627.5M   \n",
              "2                     1754.20                      3,217,226     96.0M   \n",
              "\n",
              "  GPU memory during training [MB]  \n",
              "0                          939.00  \n",
              "1                         2037.00  \n",
              "2                         1263.00  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /Users/slrpz/Downloads/ECE361E/HW3_files/table1.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = os.path.abspath('.')\n",
        "\n",
        "LOG_FILES = [\n",
        "    os.path.join(ROOT, 'vgg11_out'),\n",
        "    os.path.join(ROOT, 'vgg16_out'),\n",
        "    os.path.join(ROOT, 'mobilenet_out'),\n",
        "]\n",
        "\n",
        "def _parse_flops_to_m(flops_str: str):\n",
        "    # e.g. '306.6M' or '0.123G' (just in case)\n",
        "    m = re.match(r'^\\s*([0-9]*\\.?[0-9]+)\\s*([KMG]?)\\s*$', flops_str.strip(), re.IGNORECASE)\n",
        "    if not m:\n",
        "        return None\n",
        "    val = float(m.group(1))\n",
        "    unit = m.group(2).upper()\n",
        "    if unit == '':\n",
        "        # assume raw FLOPs\n",
        "        return val / 1e6\n",
        "    if unit == 'K':\n",
        "        return val / 1e3\n",
        "    if unit == 'M':\n",
        "        return val\n",
        "    if unit == 'G':\n",
        "        return val * 1e3\n",
        "    return None\n",
        "\n",
        "def parse_table1_block(text: str):\n",
        "    # Find the last Table 1 block in the file\n",
        "    idx = text.rfind('--- Table 1 Results ---')\n",
        "    if idx == -1:\n",
        "        return None\n",
        "    block = text[idx:].splitlines()\n",
        "    out = {}\n",
        "    for line in block[:30]:\n",
        "        line = line.strip()\n",
        "        if line.startswith('Model:'):\n",
        "            out['Model'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('Training accuracy'):\n",
        "            out['Training accuracy [%]'] = float(line.split(':', 1)[1].strip())\n",
        "        elif line.startswith('Test accuracy'):\n",
        "            out['Test accuracy [%]'] = float(line.split(':', 1)[1].strip())\n",
        "        elif line.startswith('Total time for training'):\n",
        "            out['Total time for training [s]'] = float(line.split(':', 1)[1].strip())\n",
        "        elif line.startswith('Number of trainable parameters'):\n",
        "            out['Number of trainable parameters'] = int(line.split(':', 1)[1].strip().replace(',', ''))\n",
        "        elif line.startswith('FLOPs:'):\n",
        "            flops_raw = line.split(':', 1)[1].strip()\n",
        "            out['FLOPs [M]'] = _parse_flops_to_m(flops_raw)\n",
        "            out['FLOPs (raw)'] = flops_raw\n",
        "        elif line.startswith('GPU memory during training'):\n",
        "            out['GPU memory during training [MB]'] = float(line.split(':', 1)[1].strip())\n",
        "    return out if out.get('Model') else None\n",
        "\n",
        "rows = []\n",
        "missing = []\n",
        "for path in LOG_FILES:\n",
        "    if not os.path.exists(path):\n",
        "        missing.append(os.path.basename(path))\n",
        "        continue\n",
        "    with open(path, 'r', errors='ignore') as f:\n",
        "        metrics = parse_table1_block(f.read())\n",
        "    if metrics is None:\n",
        "        missing.append(os.path.basename(path) + ' (no Table 1 block found)')\n",
        "    else:\n",
        "        rows.append(metrics)\n",
        "\n",
        "if missing:\n",
        "    print('Missing / incomplete logs:', ', '.join(missing))\n",
        "\n",
        "df_raw = pd.DataFrame(rows)\n",
        "\n",
        "# Keep just the Table 1 columns, in the assignment order\n",
        "cols = [\n",
        "    'Model',\n",
        "    'Training accuracy [%]',\n",
        "    'Test accuracy [%]',\n",
        "    'Total time for training [s]',\n",
        "    'Number of trainable parameters',\n",
        "    'FLOPs [M]',\n",
        "    'GPU memory during training [MB]',\n",
        "]\n",
        "df_raw = df_raw[[c for c in cols if c in df_raw.columns]].copy()\n",
        "\n",
        "# Clean model names for consistency\n",
        "if 'Model' in df_raw.columns:\n",
        "    df_raw['Model'] = df_raw['Model'].str.strip().str.upper().replace({'MOBILENET': 'MOBILENET-V1'})\n",
        "\n",
        "# Display-friendly formatting (keep df_raw numeric for CSV)\n",
        "df = df_raw.copy()\n",
        "\n",
        "# Formatting helpers for display\n",
        "if 'Number of trainable parameters' in df.columns:\n",
        "    df['Number of trainable parameters'] = df['Number of trainable parameters'].map(lambda x: f'{int(x):,}')\n",
        "if 'FLOPs [M]' in df.columns:\n",
        "    df['FLOPs [M]'] = df['FLOPs [M]'].map(lambda x: '' if pd.isna(x) else f'{float(x):.1f}M')\n",
        "for c in ['Training accuracy [%]', 'Test accuracy [%]']:\n",
        "    if c in df.columns:\n",
        "        df[c] = df[c].map(lambda x: f'{float(x):.2f}')\n",
        "for c in ['Total time for training [s]', 'GPU memory during training [MB]']:\n",
        "    if c in df.columns:\n",
        "        df[c] = df[c].map(lambda x: f'{float(x):.2f}')\n",
        "\n",
        "df\n",
        "\n",
        "# Also export a machine-readable CSV for your report workflow\n",
        "out_csv = os.path.join(ROOT, 'table1.csv')\n",
        "df_raw.to_csv(out_csv, index=False)\n",
        "print('Saved:', out_csv)\n",
        "\n",
        "# Display the table explicitly\n",
        "from IPython.display import display\n",
        "display(df)\n",
        "\n",
        "# Also export a machine-readable CSV for your report workflow\n",
        "out_csv = os.path.join(ROOT, 'table1.csv')\n",
        "df_raw.to_csv(out_csv, index=False)\n",
        "print('Saved:', out_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f941732b",
      "metadata": {},
      "source": [
        "### Problem 1 – Question 3: VGG11 vs VGG16 comparison\n",
        "\n",
        "- Accuracy vs. epochs: VGG11 reaches higher accuracy in the very early epochs, but VGG16 quickly catches up and ultimately achieves the better final test accuracy. After 100 epochs, VGG11 ends at 76.08% test accuracy while VGG16 reaches 78.46%, so VGG16 provides about +2.4 percentage points better generalization.\n",
        "- Training accuracy and overfitting: Both models achieve very high training accuracy (VGG11: 99.07%, VGG16: 98.35%). The gap between train and test accuracy indicates some overfitting for both, but the gap is not dramatically worse for VGG16, even though it is deeper.\n",
        "- Training time: VGG16 takes longer to train (1622.58 s) than VGG11 (1468.63 s), roughly 10% more wall‑clock time for the same number of epochs on the same hardware.\n",
        "- Model size and FLOPs: VGG16 is substantially heavier:\n",
        "  - Parameters: VGG11 has 9,750,922 trainable parameters, while VGG16 has 15,245,130 (about 1.6× more).\n",
        "  - FLOPs: VGG11 requires 306.6M FLOPs per forward pass, while VGG16 requires 627.5M FLOPs (about 2× more compute).\n",
        "- GPU memory usage: VGG16 also uses more GPU memory during training (2037 MB) than VGG11 (939 MB), which matters if GPU memory is a bottleneck.\n",
        "\n",
        "VGG16 provides slightly better test accuracy (about 2–3 percentage points) but at the cost of roughly 2 FLOPs, 1.6 parameters, higher GPU memory usage, and slightly longer training time. If maximum accuracy is the only goal and compute/memory are plentiful, VGG16 is preferable. However, in edge‑or resource‑constrained settings—where training and inference cost matter as much as accuracy—VGG11 is more attractive because it is significantly cheaper while achieving only a modestly lower test accuracy. In this homework context, where we care about efficiency on edge devices, we would generally prefer VGG11."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
